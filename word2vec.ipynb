{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "426db7c2-ef0f-46f0-8a16-239f8d25560b",
   "metadata": {},
   "source": [
    "From *Tensorflow*:\n",
    "\n",
    "**word2vec** is not a singular algorithm, rather, it is a family of model architectures and optimizations that can be used to learn word embeddings from large datasets. Embeddings learned through word2vec have proven to be successful on a variety of downstream natural language processing tasks.\n",
    "\n",
    "Representations of words:\n",
    "\n",
    "- **Bag-of-words**: predicts a word given the neighboring context\n",
    "- **Skip-gram**: predicts the neighboring context of a word, given the word itself\n",
    "    - **Loss** would be the propability of all words in dictionary to be in the *conext*, with huge dictionaries, this would pose a problem\n",
    "    - So noise contrastive estimation (**NCE**) loss is used as an efficient approximation for a full **softmax**\n",
    "        - NCE uses **Negative Sampling**\n",
    "\n",
    "From *Tensorflow*:\n",
    "\n",
    "A negative sample is defined as a (`target_word`, `context_word`) pair such that the `context_word` does not appear in the `window_size` neighborhood of the `target_word`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "23019073-2b01-4e6c-98e6-834e4120cd70",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import re\n",
    "import string\n",
    "import tqdm\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cd25ae9a-87c7-4f99-bd23-72eee5605c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "AUTOTUNE = tf.data.AUTOTUNE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "076f4bd2-dca2-44b9-b4db-4ef4459d1034",
   "metadata": {},
   "source": [
    "# Tokenize and Vectorize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7f0b81c0-d672-42e6-b19a-fbcf5cabbe17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    }
   ],
   "source": [
    "# tokenize\n",
    "sentence = \"The wide road shimmered in the hot sun\"\n",
    "tokens = list(sentence.lower().split())\n",
    "print(len(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cc69ee5e-1803-4199-89c1-fcae7c37307e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'<pad>': 0, 'the': 1, 'wide': 2, 'road': 3, 'shimmered': 4, 'in': 5, 'hot': 6, 'sun': 7}\n"
     ]
    }
   ],
   "source": [
    "# create vocab\n",
    "vocab, index = {}, 1  # start indexing from 1\n",
    "vocab['<pad>'] = 0  # add a padding token\n",
    "for token in tokens:\n",
    "  if token not in vocab:\n",
    "    vocab[token] = index\n",
    "    index += 1\n",
    "vocab_size = len(vocab)\n",
    "print(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4b3e801f-fbd5-4cf0-9caf-1044d1544224",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: '<pad>', 1: 'the', 2: 'wide', 3: 'road', 4: 'shimmered', 5: 'in', 6: 'hot', 7: 'sun'}\n"
     ]
    }
   ],
   "source": [
    "# inverse vocab, to use numerical indexes\n",
    "inverse_vocab = {index: token for token, index in vocab.items()}\n",
    "print(inverse_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cb2e7f15-670a-421c-989c-b1b24984b238",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 4, 5, 1, 6, 7]\n"
     ]
    }
   ],
   "source": [
    "# vectorize\n",
    "example_sequence = [vocab[word] for word in tokens]\n",
    "print(example_sequence)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "506f958b-6010-48b9-aeea-b4b22686c011",
   "metadata": {},
   "source": [
    "# Skip-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8ffc17e9-7d74-4cb6-bdd9-9f2c35a85e22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26\n"
     ]
    }
   ],
   "source": [
    "window_size = 2\n",
    "\n",
    "positive_skip_grams, _ = tf.keras.preprocessing.sequence.skipgrams(\n",
    "      example_sequence,\n",
    "      vocabulary_size=vocab_size,\n",
    "      window_size=window_size,\n",
    "      negative_samples=0\n",
    ")\n",
    "print(len(positive_skip_grams))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "535db7ae-7fef-4e78-9090-5c6d6e635c3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 7): (the, sun)\n",
      "(7, 6): (sun, hot)\n",
      "(4, 3): (shimmered, road)\n",
      "(3, 4): (road, shimmered)\n",
      "(1, 3): (the, road)\n"
     ]
    }
   ],
   "source": [
    "# positive sampling\n",
    "for target, context in positive_skip_grams[:5]:\n",
    "  print(f\"({target}, {context}): ({inverse_vocab[target]}, {inverse_vocab[context]})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "af39bcbd-5800-4f22-86aa-2615373aaa62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([2 1 4 3], shape=(4,), dtype=int64)\n",
      "['wide', 'the', 'shimmered', 'road']\n"
     ]
    }
   ],
   "source": [
    "# negative sampling\n",
    "target_word, context_word = positive_skip_grams[0]\n",
    "\n",
    "num_ns = 4 # Set the number of negative samples per positive context\n",
    "\n",
    "context_class = tf.reshape(tf.constant(context_word, dtype=\"int64\"), (1, 1))\n",
    "\n",
    "negative_sampling_candidates, _, _ = tf.random.log_uniform_candidate_sampler(\n",
    "    true_classes=context_class,  # class that should be sampled as 'positive'\n",
    "    num_true=1,  # each positive skip-gram has 1 positive context class\n",
    "    num_sampled=num_ns,  # number of negative context words to sample\n",
    "    unique=True,  # all the negative samples should be unique\n",
    "    range_max=vocab_size,  # pick index of the samples from [0, vocab_size]\n",
    "    seed=SEED,  # seed for reproducibility\n",
    "    name=\"negative_sampling\"  # name of this operation\n",
    ")\n",
    "print(negative_sampling_candidates)\n",
    "print([inverse_vocab[index.numpy()] for index in negative_sampling_candidates])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
